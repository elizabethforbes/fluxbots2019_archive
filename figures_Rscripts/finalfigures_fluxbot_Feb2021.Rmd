---
title: "finalfigures_fluxbot_Feb2021"
author: "Elizabeth Forbes"
date: "2/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Final figures using the final, trimmed dataset:

This document is a final version of the doc to create the figures used in the fluxbot methods paper. The code is taken/cleaned from existing experimental Rmd files and aggregated here so all figures can be produced from one document. The final data was downloaded/cleaned in "finaldataset_fluxbots_Feb2021.Rmd", and is named fluxdat_final here. Figures that are not predicated on the final dataset (e.g. the Allan variance figure, which uses all raw data) will also be rounded up here.

# Density distribution figure:
This chunk makes the density distribution figure to look at the spread and skew of the fluxes in the cleaned dataset, and try to replicate figure two in the 2013 paper "Spatial heterogeneity of soil respiration in a seasonal rainforest with complex terrain", by Song et al. (E.g. a figure with the soil respiration in umol/m2/sec on the x-axis, and the PDF on the y-axis, with an inset figure of the same except the soil respiration is log transformed.) 
```{r density_distribution}
library(ggplot2)
library(tidyverse)
library(scales)

# probability density function in GGplot: 
dens_g <- ggplot(fluxdat_final, aes(x=flux_umol_m2_sec, y=0.3))+
  # add horizontal boxplot, narrow (0.05) width
  geom_boxplot(width = 0.05, fill="lightblue", outlier.colour = "darkred", outlier.shape = 1, outlier.alpha = 0.2)+
  # add density plot
  geom_density(aes(x=flux_umol_m2_sec), fill="lightblue", inherit.aes = FALSE)+
  scale_fill_discrete()+
  theme_classic()+
  xlab(bquote('soil carbon flux ('*mu~'mol'~CO[2]~m^-2~s^-1*')'))+
  ylab('probability density function')

# need to make plot of log-transformed data, to add as inset to the above graph
log_g <- ggplot(data=fluxdat_final, aes(x=flux_umol_m2_sec))+
  geom_density(aes(x=flux_umol_m2_sec), fill="lightblue", alpha=0.4, inherit.aes = FALSE)+
  scale_x_log10(labels=scales::comma)+
  theme_classic()+
  xlab("log transformed soil carbon flux")+
  theme(axis.title.y = element_blank())+
  theme(axis.title.x = element_text(vjust = -1))

# Okay now put them together with an inset. See the following for source code: https://www.r-bloggers.com/2019/02/plots-within-plots-with-ggplot2-and-ggmap/
dens_g + annotation_custom(ggplotGrob(log_g), xmin=25, xmax=45,
                       ymin=0.1, ymax = 0.25)
```


# Visualization of fluxes over one random week:
```{r examplefluxes_overtime}
library(scales)
library(lubridate)

# It's possible I'll want to play around with other randomly-pulled bots and weeks; but in essence, this figure is demonstrating one 7-day period of time in flux at one individual bot.
# select the NO OS2 bot:
no_os2_fluxes <- fluxdat_final %>% 
  filter(treatment == "O" & location == "Open Soil" & replicate == 2) %>% 
  filter(month == 9) %>% 
  filter(day>0 & day<9)
  # filter(day>12 & day<17)

# plot data from September 1st through 7th:
no_os2_fluxes %>% 
  ggplot(aes(x=timestamp, y=flux_umol_m2_sec))+
  geom_point(color="salmon")+
  geom_line(linetype = "dotted", color = "black")+
  scale_x_datetime(labels = date_format("%b. %e, %H:%M"),
                   date_breaks = "1 day",
                   date_minor_breaks = "1 hour")+
  theme_classic()+
  theme(axis.title = element_text(vjust = 0.25),
        axis.text.x = element_text(vjust = 0.7, hjust = .8, angle = 15))+
  labs(x=NULL,
       y=expression(paste("flux, "~mu*"mol"~"/m"^2)*"/sec"),
       title = "No wildlife or cattle allowed, open soil site #2")+
  geom_vline(xintercept = as.numeric(ymd_h(
    c("2019-09-1 0", "2019-09-2 ", "2019-09-3 0","2019-09-4 0",
      "2019-09-5 0","2019-09-6 0","2019-09-7 0", "2019-09-8 0"))),
    linetype="dashed", color = "#66A182", size=.6)

```

# Visualization of raw data over same week (raw data):
```{r rawdata_overtime}

# read in raw datafile, also in project folder (not labeled 'output', just labeled with name of the site):
no_os2_raw <- read.csv("NO OS2.csv", header=TRUE)

no_os2_raw$Timestamp <- as_datetime(no_os2_raw$Unix.Epoch.Time)

# add month, day, hour columns:
no_os2_raw$month <- format(no_os2_raw$Timestamp, "%m")
no_os2_raw$day <- format(no_os2_raw$Timestamp, "%d")
no_os2_raw$hour <- format(no_os2_raw$Timestamp, "%H")

# calculate a 20s rolling average to show how it cuts down on variability but maintains trends in the raw data:
no_os2_raw <- no_os2_raw %>%
    dplyr::arrange(Timestamp) %>% # put in timestamp order
    dplyr::group_by(month, day, hour) %>% 
    dplyr::mutate(raw_20sec = zoo::rollmean(Raw.CO2.PPM, k = 20, fill = NA)) #calculate rolling average with 20s window

# plot same 7-day period from above chunk, with raw data in gray and 20s smoothed data in same salmon on top:
# set vector of breaks first:
mybreaks <- lubridate::ymd_hm(c("2019-09-01 00:00","2019-09-02 00:00","2019-09-3 00:00","2019-09-4 00:00","2019-09-5 00:00","2019-09-6 00:00", "2019-09-7 00:00", "2019-09-8 00:00", "2019-09-09 00:00"))

# filter the data by month, day
no_os2_raw %>% 
  filter(month == "09") %>%
  filter(day == "01" | day == "02" | day == "03" | 
           day == "04" | day == "05" | day == "06" | 
           day == "07" | day == "08") %>%             #days and months currently coded in character class
  ggplot()+
  geom_point(aes(x=Timestamp, y=Raw.CO2.PPM), color="gray", alpha=0.4)+ #raw data
  geom_point(aes(x=Timestamp, y=raw_20sec), color="salmon", alpha=0.2)+
  theme_classic()+
  scale_x_datetime(breaks = mybreaks, date_labels = "%b. %e, %H:%M")+
  labs(x = NULL, y = expression(paste("concentration of"~CO[2]~", PPM")))+
  geom_vline(xintercept = mybreaks, linetype="dashed", color = "#66A182", size=.6) +
  theme(axis.title = element_text(vjust = 0.25), 
        axis.text.x = element_text(vjust = 0.5, angle = 20))+
  ggtitle("No wildlife or cattle allowed, open soil site #2")

```

# Allan variance figure (raw data):
This figure will go in the results section of the methods paper, and will demonstrate how much time is optimal to average the data by (taken every second; averaged to every X seconds). Taking the Allan Variance will allow us to account for the fact that there is some temporal variability in the raw data, and it can be 'cleaned up' via averaging without negatively impacting the results.
This figure will show:
- in a period of time during which CO2 is constant (e.g. steady-state), what do the functions look like as a result of averaging time around a constant value (e.g. 20s)?
- what is the noise around this averaging result?
This data will allow us to:
- determine size of averaging window for raw data processing prior to regression and flux calculation.

```{r Allan_variance}

# import data: in same project folder:
allan <- read.csv("allen_variance_results.csv", header=TRUE)

# explore data: what does it look like? visual confirmation of 20s rolling average as maintaining optimal temporal detail and reducing the noise from per-second raw data:
plot(allan$tau..sec., allan$std..ppm.)

# final plot:
allan %>% 
  ggplot(aes(tau..sec., std..ppm.))+
  geom_point(colour = "black", size = 3, alpha = 1/3)+
  theme_classic()+
  labs(x="averaging time in seconds (\u03C4)", #unicode value for small tau
       y="Allan Variance (PPM)")+
  geom_vline(xintercept = 20, colour = "red", linetype = "longdash")+
  scale_x_continuous(breaks = seq(0, 120, 20))
```

Comparison of linear vs. quadratic regression:
```{r linearvsquadratic}

# add minute col to your already-messed with raw datafile, NO OS2:
no_os2_raw$minute <- format(no_os2_raw$Timestamp, "%M")

# using wide-form data here, with layers:
g1 <- no_os2_raw %>% 
  filter(month == "09") %>%
  filter(day == "03") %>% 
  filter(hour == "08") %>% 
  filter(minute > "55") %>% 
  ggplot()+
  geom_point(aes(x=Timestamp, y=Raw.CO2.PPM), color="gray", alpha = 0.6)+
  geom_point(aes(x=Timestamp, y=raw_20sec), color="salmon", alpha=0.8)+
  theme_bw()+
  labs(x = NULL, y = expression(paste("PPM"~"CO"[2])))+
  geom_smooth(mapping = aes(x = Timestamp, y = raw_20sec),
              method = 'lm', formula = y ~ poly(x,2), se= FALSE,
              color = "darkred")+ # polynomial regression
  ggtitle("Sept. 3rd, 2019, 8:55-9:00")+
  ylim(250,500)

g2 <- no_os2_raw %>% 
  filter(month == "09") %>%
  filter(day == "04") %>% 
  filter(hour == "07") %>% 
  filter(minute > "55") %>% 
  ggplot()+
  geom_point(aes(x=Timestamp, y=Raw.CO2.PPM), color="gray", alpha=0.6)+ #raw data
  geom_point(aes(x=Timestamp, y=raw_20sec), color="darkgoldenrod2", alpha=0.9)+ #20s averaged data, green
  theme_bw()+
  labs(x = NULL, y = NULL)+
  geom_smooth(mapping = aes(x = Timestamp, y = raw_20sec),
              method = 'glm', formula = y ~ x, se= FALSE,
              color = "darkred")+ #linear regression 
  ggtitle("Sept. 4th, 2019, 7:55-8:00")+
  ylim(250,500)

library(gridExtra)
grid.arrange(g1, g2, nrow = 1)
```

# Visualization of the breakdown of QAQC flags (uncleaned 20s mean flux data):
Here I will create a visualization of the fluxes that were removed from the overall final dataset due to their QAQC scores being over 11 total; I will need to do a bit more data cleaning here to create that dataset. Any row with a QAQC value over 11 was pulled from the final dataset.
Remember that our flags are:
			1 - if dP > dP_max (default dP_max = 10 hPa) (1)
			2 - if dT > dT_max (default dT_max = 2.5 deg-C) (10)
			3 - if CO2 > CO2_max (default CO2_max = 3000 ppm) (100)
			4 - if n_obs < min_obs (default min_obs = 270) (1000)
			5 - if dCO2 < dCO2_min (default dCO2_min = 10 ppm) (10000)
			6 - if sCO2 < 0 (sCO2 is difference between last CO2 ppm value and first value) (100000)
			7 - mCO2 is True (e.g. last value is less than the mean, and first value is greater than the mean) (1000000) 

# visualization of QAQC breakdown, using a tree map. (https://www.r-graph-gallery.com/treemap.html). 
```{r qaqc_treemap}
library(treemap)

# rename original fluxdata_20s_2019 (e.g. all the data with the 'right' timestamps but including bad-qaqc data) df for manipulation:
qaqcdat <- fluxdata_20s_2019
# qaqcdat <- fluxdata_20s # if you want to include timestamp errors

# remove termite soil and pre-Aug-23rd data;
qaqcdat <- qaqcdat %>% 
  filter(location == "Open Soil" | location == "Under Tree") %>%  # remove termite soil data...
  filter(timestamp > "2019-08-22 23:59:59") %>%                   #...data before Aug. 23rd...
  filter(qaqc_flags > 11)                                         # all data with flags > 11

# remove all data from October for NO OS 1, when it had the 'rotating lid': first, make an 'exclude this' df for those points.
noos1oct <- qaqcdat %>% 
  filter(treatment == "O" & location == "Open Soil" & replicate == 1) %>% 
  filter(month > 9)
# then, use anti_join (dplyr) to remove those rows in 'noos1oct' from 'qaqcdat':
qaqcdat <- anti_join(qaqcdat, noos1oct)

# now we have a final qaqc 'bad' flags dataset.  Next up: graphical interpretation of it. Summarize the data:
qaqc_sum <- qaqcdat %>% 
  group_by(qaqc_flags) %>% 
  summarise(counts = n())

# add column of 'reasons' to summed df, in order
qaqc_sum$reason <- c("CO2(max) > 3000ppm", 
            "# observations < 270",
            "CO2(max) > 3000ppm & dCO2 < 10ppm",
            "CO2(max) > 3000ppm & dCO2 < 10ppm & dTemp > 2.5C",
            "dCO2 < 10ppm & # observations < 270",
            "negative net dCO2",
            "negative net dCO2 & dTemp > 2.5C",
            "negative net dCO2 & # observations < 270")

treemap(qaqc_sum,
        index = "reason",
        vSize = "counts",
        type = "index",
        palette = "Paired",
        # fontcolor.labels = "white",
        # fontcolor.labels = c("transparent"), # remove labels, I'll customize to match other figs
        title = "qaqc",
        fontsize.title = 0) # remove title, this is clumsy but it works

# note to self: made this plot prettier in Affinity Designer, with specialized font, for publication. Could work within R Studio in this plot-making script to do it in R Studio instead.
```

A figure exploring the 'rotating head' data, (NO OS1 data from October 2019).
```{r rotatinghead}

# plot just the October (e.g. rotating head) data for NO OS1
# isolate those data: should be 229 total points
noos1_rot <- fluxdata_20s_2019_qaqc %>%
  filter(treatment == "O" & location == "Open Soil" & replicate == 1) %>% # this col==this AND this other col==this...
  filter(month == 10)

# plot: ambient in blue and fluxes in red
noos1_rot %>%
  ggplot(aes(x=timestamp))+  
  geom_point( aes(y=ambient_CO2_ppm, alpha = 0.3), color = "blue")+
  geom_line( aes(y=flux_umol_m2_sec*100, alpha = 0.3), color="red")+
  scale_y_continuous(name = "ambient CO2 (ppm) (blue)",
                     sec.axis = sec_axis(~./100, name = "flux (umol/m2/sec) (red)"))+
  theme_classic()+
  theme(legend.position = "none")+
  scale_x_datetime(date_breaks = "1 day",
                   date_labels = "%b %d, %H:%M")+ # separate ticks by date, one day at a time+
  # scale_y_continuous(limits = c(0,4000))+
  theme(axis.text.x = element_text(angle=25, hjust = 1, size=7))

# want to examine each time chunk (e.g. how many days an individual head was on the location before being swapped according to our calendar). The following is clumsy but it works: separates out each period of time and adds an identifier called 'rotation'. These are roughly around 10am unless noted otherwise in the field notes; some days had times written at the header with date, and some did not, but generally it all happened between 9am-12pm and can be corroborated by looking at where the ambient data shifts visibly.

d1 <- noos1_rot %>%   
  filter(timestamp >= as_datetime("2019-10-05 00:00:00") & 
           timestamp <= as_datetime("2019-10-08 10:00:00")) %>% # notes indicate between 9 and 10
  add_column(rotation = 1)
d2 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-08 10:00:00") &
           timestamp <= as_datetime("2019-10-10 12:00:00")) %>% # notes indicate before noon
  add_column(rotation = 2)
d3 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-10 12:00:00") &
           timestamp <= as_datetime("2019-10-12 12:00:00")) %>% #no time; plot indicates ~ <12pm?
  add_column(rotation = 3)
d4 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-12 12:00:00") &
           timestamp <= as_datetime("2019-10-15 10:00:00")) %>% #no time; plot indicates ~ <10am?
  add_column(rotation = 4)
d5 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-15 10:00:00") &
           timestamp <= as_datetime("2019-10-17 12:00:00")) %>% #no time; plot indicates ~ <12pm?
  add_column(rotation = 5)
d6 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-17 12:00:00") &
           timestamp <= as_datetime("2019-10-19 12:00:00")) %>% #no time; assume ~ <12pm
  add_column(rotation = 6)
d7 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-19 12:00:00") &
           timestamp <= as_datetime("2019-10-22 10:00:00")) %>% #no time; plot indicates ~ <10am? assume morning due to note on 'removing covers after rainfall' which always happened in the morning as soon as possible to avoid blocking sunlight
  add_column(rotation = 7)
d8 <- noos1_rot %>%  
  filter(timestamp > as_datetime("2019-10-22 10:00:00") &
           timestamp <= as_datetime("2019-10-24 12:00:00")) %>% #no time; plot indicates ~ 12pm?
  add_column(rotation = 8)
d9 <- noos1_rot %>%   
  filter(timestamp > as_datetime("2019-10-24 12:00:00")) %>% 
  add_column(rotation = 9)

# bind new cols together with identifier column
d10 <- rbind(d1, d2, d3, d4, d5, d6, d7, d8, d9)

# vector of approximate times when heads were swapped (using midnight as proxy even tho heads were swapped during fieldwork during the day)
mybreaks <- lubridate::ymd_hm(c("2019-10-08 10:00","2019-10-10 12:00","2019-10-12 12:00","2019-10-15 10:00","2019-10-17 12:00","2019-10-19 12:00", "2019-10-22 10:00", "2019-10-24 12:00"))

# vector of sample sizes per group (e.g. 'rotation')
n_lab <- paste(levels(d10$rotation), "\nN = ",table(d10$rotation), "",sep="")
n_lab <- as.numeric(n_lab)

# plot data in boxplot form for fluxes, line or points for ambient:
d10 %>%
  ggplot(aes(x=timestamp))+  
  geom_line( aes(y=ambient_CO2_ppm, group=rotation), color = "darkgoldenrod2", size=1)+
  geom_boxplot( aes(y=flux_umol_m2_sec*100, group=rotation), fill="salmon", alpha=0.3,
                outlier.colour="darkred", varwidth = TRUE)+
  scale_y_continuous(name = "ambient CO2 (ppm) (yellow line)",
                     sec.axis = sec_axis(~./100, name = "flux (umol/m2/sec) (red boxplots)"))+
  theme_classic()+
  theme(legend.position = "none")+
  scale_x_datetime(date_breaks = "1 day",
                   date_labels = "%b %d, %H:%M")+ # separate ticks by date, one day at a time+
  theme(axis.text.x = element_text(angle=25, hjust = 1, size=7))+
  geom_vline(xintercept = mybreaks, linetype="dashed", color = "#66A182", size=.6)+
  labs(x = NULL)

```

# distribution of Quadratic and Linear calculations
This chunk will be for developing a brief visual assessment of the distribution of fluxes calculated with linear or quadratically-derived beta values.
```{r QandL}
# boxplot exploring the distribution of flux values according to whether it was calculated with a linear or quadratic regression:
box_regr <- fluxdat_final %>% 
  ggplot(aes(x=regr, y=flux_umol_m2_sec, fill=regr))+
  geom_boxplot(outlier.colour="darkred", outlier.shape=1,
                outlier.size=1)+
  scale_fill_brewer(palette = "Pastel1")+
  labs(x=NULL,
       y=expression(paste("flux, "~mu*"mol"~"/m"^2)*"/sec"))+
  theme_classic()+
  scale_x_discrete(labels=c("L" = expression(paste("calculated with linear regression"~beta)),
                            "Q" = expression(paste("calculated with quadratic regression"~beta))))+
  theme(axis.text.x = element_text(size=12),
        axis.text.y = element_text(size=10),
        axis.title.y = element_text(size = 10))+
  theme(legend.position = "none")+
  ggtitle("b")

box_regr

# # bonus plot to examine the relationship between R2 and regression type
# fluxdat_final %>%
#   filter(R2 > 0) %>%
#   ggplot(aes(x=regr, y=R2, fill=regr))+
#   geom_boxplot(outlier.colour="darkred", outlier.shape=1,
#                 outlier.size=1)+
#   scale_fill_brewer(palette = "Pastel1")+
#   labs(x=NULL,
#        y=expression(paste("R"^2)))+
#   theme_classic()+
#   scale_x_discrete(labels=c("L" = expression(paste("calculated with linear regression"~beta)),
#                             "Q" = expression(paste("calculated with quadratic regression"~beta))))+
#   theme(axis.text.x = element_text(size=12),
#         axis.text.y = element_text(size=10),
#         axis.title.y = element_text(size = 14))+
#   theme(legend.position = "none")

```

The below plot looks at distribution of regressions with quadratic beta vs. linear beta, in same figure as the above plot:
```{r QandL_2}

bar_regr <- fluxdat_final %>% 
  ggplot(aes(x=regr, fill=regr))+
  geom_bar(color="black")+
  scale_fill_brewer(palette = "Pastel1")+
  labs(x=NULL,
       y=NULL)+
  theme_classic()+
  theme(axis.title.x = element_text(size=13),
        axis.title.y = element_text(size = 10))+
  theme(legend.position = "none")+
  ylab("total flux observations")+
  # scale_x_discrete(labels=c("L" = expression(paste("calculated with linear regression"~beta)),
  #                           "Q" = expression(paste("calculated with quadratic regression"~beta))))+
  theme(axis.text.x = element_blank())+
  ggtitle("a")

# plot box_regr and bar_regr together:
library(patchwork)
patchwork <- bar_regr / box_regr
patchwork
```

Plotting max and mins of our fluxes calculated with the confidence intervals of our betas. Here we are experimenting with different visualizations of flux, measurements of error, and R2.
```{r rel_flux}

# relative flux uncertainty compared to flux estimate, filtered to isolate fluxes and R2s over 0:
fluxdat_final %>%
  filter(flux_umol_m2_sec > 0.0) %>% 
  filter(R2 > 0) %>% 
  ggplot(aes(y=rel_uncertainty*100, x=flux_umol_m2_sec))+
  geom_point(alpha=0.25)+
  theme_classic()+
  labs(x = expression(paste("flux,"~mu*"mol"~"/m"^2)*"/sec"),
       y = "relative flux uncertainty")+
  theme(axis.text = element_text(size=18),
        axis.title = element_text(size=21))+
  theme(axis.text = element_text(size=18),
        axis.title = element_text(size=21),
        axis.text.y = element_text(color = c("red", "black", "black", "black", "black")))+
  scale_y_continuous(breaks = c(100, 2500, 5000, 7500, 10000), 
                     labels = c("100", "2.5k", "5k", "7.5k", "10k"))+
  geom_hline(yintercept = 100, linetype = "dashed", color = "red")

```

The below plot visualizes relative flux uncertainty (y) against R2 values (x), with the data filtered to isolate those fluxes over 0 and those R2s over 0.
```{r rel_R1}

# relative flux uncertainty compared to R2:
fluxdat_final %>%
  filter(flux_umol_m2_sec > 0.0) %>%
  filter(R2 > 0) %>% 
  ggplot(aes(y=rel_uncertainty*100, x=R2))+
  geom_point(alpha=0.25)+
  theme_classic()+
  labs(x = expression(paste("R"^2)),
       y = "relative uncertainty (%)")+
  ylim(0,10000)+
  theme(axis.text = element_text(size=18),
        axis.title = element_text(size=21),
        axis.text.y = element_text(color = c("red", "black", "black", "black", "black")))+
  scale_y_continuous(breaks = c(100, 2500, 5000, 7500, 10000), 
                     labels = c("100", "2.5k", "5k", "7.5k", "10k"))+
  geom_hline(yintercept = 100, linetype = "dashed", color = "red")
```

The below plot visualizes flux (x) against R2 values (y), with the data filtered to isolate those fluxes over 0 and those R2s over 0.  The three above plots are combined for the final figure for publication using Affinity Designer.
```{r flux_R2}

# flux compared to R2:
fluxdat_final %>%
  filter(flux_umol_m2_sec > 0.0) %>%
  filter(R2 > 0) %>%
  ggplot(aes(x=flux_umol_m2_sec, y=R2))+
  geom_point(alpha=0.25)+
  theme_classic()+
  labs(y = expression(paste("R"^2)),
       x = expression(paste("flux,"~mu*"mol"~"/m"^2)*"/sec"))+
  theme(axis.text = element_text(size=18),
        axis.title = element_text(size=21))

```

